{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87baf8f3",
   "metadata": {},
   "source": [
    "Setting up Doom Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9e0cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipinstall vizdoom and clone repo in new folder\n",
    "#!cd github & git clone https://github.com/Farama-Foundation/ViZDoom.git\n",
    "\n",
    "#import vizdoom to setup game environment\n",
    "from vizdoom import *\n",
    "\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#pip install and import gym environment\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37732746",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizDoomGym(Env):\n",
    "    #called when env is started > game\n",
    "    def __init__(self,render=False):\n",
    "        \n",
    "        #inherit from Env import\n",
    "        super().__init__()\n",
    "        \n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config(\"github/VizDoom/scenarios/basic.cfg\")\n",
    "        \n",
    "        #Disable or enable window visiblity when game is running\n",
    "        if render == False:\n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "        \n",
    "        self.game.init()\n",
    "    \n",
    "        \n",
    "        \n",
    "        #create obs and action space\n",
    "        #low/high indicates pixel vals\n",
    "        self.observation_space = Box(low=0,high=255,shape=(100,160,1),dtype=np.uint8)\n",
    "        self.action_space = Discrete(3)\n",
    "    #tale actons\n",
    "    def step(self,action):\n",
    "        actions = np.identity(3,dtype=np.uint8)\n",
    "        \n",
    "        #take action, make_action() returns reward value for taking ste\n",
    "        #2nd para is frame skip to give time between taking action and receiving result\n",
    "        reward = self.game.make_action(actions[action],4)\n",
    "        \n",
    "        #if something is returned from game_state()\n",
    "        if self.game.get_state():\n",
    "            #get game state to grab screen image\n",
    "            state = self.game.get_state().screen_buffer\n",
    "            #apply grayscale\n",
    "            state = self.grayscale(state)\n",
    "            #use game state to grab game vars, i.e. ammo\n",
    "            ammo = self.game.get_state().game_variables[0]\n",
    "            info = ammo\n",
    "        #game_state returns nothing/errors out\n",
    "        else:\n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = 0\n",
    "        \n",
    "        info = {\"info\":info}\n",
    "        \n",
    "        done = self.game.is_episode_finished()\n",
    "        \n",
    "        \n",
    "        return state,reward,done,info\n",
    "    def render():\n",
    "        pass\n",
    "    \n",
    "    #resets game\n",
    "    def reset(self):\n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(state)\n",
    "    \n",
    "    #grayscale frame and scales down image, to make training faster\n",
    "    def grayscale(self,observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation,0,-1),cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160,100),interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize,(100,160,1))\n",
    "        return state\n",
    "    #close the game\n",
    "    def close(self):\n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b07ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b1ef7",
   "metadata": {},
   "source": [
    "Setting up callback for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd66522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saves tensorboard log file after training, go into PPO_n and run tensorboard --logdir=. then open local host link\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n",
    "    \n",
    "CHECKPOINT_DIR = './train/train_basic'\n",
    "LOG_DIR = './logs/log_basic'\n",
    "\n",
    "#after every 10k steps of training model, save version of pytorch weights for RL agent\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de597f4e",
   "metadata": {},
   "source": [
    "Proximal Policy Optimization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2dc3bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./logs/log_basic\\PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -73.1    |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | -88.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005784576 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.000243    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | 0.00243     |\n",
      "|    value_loss           | 2.46e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -73.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011579394 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0774      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    value_loss           | 3.18e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 24.9        |\n",
      "|    ep_rew_mean          | -35.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021010567 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.97e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.000598   |\n",
      "|    value_loss           | 3.42e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 23.4        |\n",
      "|    ep_rew_mean          | -19.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013960407 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.00831     |\n",
      "|    value_loss           | 3.29e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.2        |\n",
      "|    ep_rew_mean          | -5.43       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 35          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 343         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019410994 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.67e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.000429   |\n",
      "|    value_loss           | 4.36e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 14.7       |\n",
      "|    ep_rew_mean          | 26.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 32         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 434        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02402844 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.998     |\n",
      "|    explained_variance   | 0.446      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.85e+03   |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.000673  |\n",
      "|    value_loss           | 3.86e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.1        |\n",
      "|    ep_rew_mean          | 13.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 533         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049302142 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.998      |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.0162      |\n",
      "|    value_loss           | 2.85e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.1        |\n",
      "|    ep_rew_mean          | -4.58       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 627         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018758364 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.946      |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    value_loss           | 3.5e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.4        |\n",
      "|    ep_rew_mean          | -6.69       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 704         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015181847 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.943      |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 866         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    value_loss           | 3.48e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.8        |\n",
      "|    ep_rew_mean          | 47.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025873838 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.918      |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | 0.00101     |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.8        |\n",
      "|    ep_rew_mean          | 36.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 891         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023465272 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.65e+03    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | 0.00917     |\n",
      "|    value_loss           | 3e+03       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.15        |\n",
      "|    ep_rew_mean          | 64.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 27          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 964         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017237198 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.851      |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.8        |\n",
      "|    ep_rew_mean          | 50.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1013        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020061154 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 2.5e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.5        |\n",
      "|    ep_rew_mean          | 52          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 28          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 1062        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048436888 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 560         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.74        |\n",
      "|    ep_rew_mean          | 60          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 1113        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032989547 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 362         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    value_loss           | 1.54e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 7.43       |\n",
      "|    ep_rew_mean          | 68.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 29         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 1167       |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04463753 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.646     |\n",
      "|    explained_variance   | 0.704      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 569        |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | 0.0102     |\n",
      "|    value_loss           | 1.83e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.44        |\n",
      "|    ep_rew_mean          | 68          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 1218        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044537958 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.631      |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 722         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | 0.0284      |\n",
      "|    value_loss           | 1.13e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.42        |\n",
      "|    ep_rew_mean          | 74.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 1271        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024999699 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 294         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | 0.000742    |\n",
      "|    value_loss           | 1.02e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.13        |\n",
      "|    ep_rew_mean          | 64.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 1333        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.067504786 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 320         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.0188      |\n",
      "|    value_loss           | 896         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.19        |\n",
      "|    ep_rew_mean          | 65.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 1399        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025863726 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 539         |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | 0.00222     |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 6.34      |\n",
      "|    ep_rew_mean          | 72.6      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 30        |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 1472      |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0386338 |\n",
      "|    clip_fraction        | 0.321     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.513    |\n",
      "|    explained_variance   | 0.688     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 766       |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | 0.000873  |\n",
      "|    value_loss           | 1.02e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.24        |\n",
      "|    ep_rew_mean          | 84.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1544        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.066361316 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.375      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 335         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.00468     |\n",
      "|    value_loss           | 986         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.37       |\n",
      "|    ep_rew_mean          | 79.6       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 1607       |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10943699 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.323     |\n",
      "|    explained_variance   | 0.66       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 140        |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    value_loss           | 425        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.69        |\n",
      "|    ep_rew_mean          | 76.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 1668        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054730915 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.328      |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.0346      |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.8         |\n",
      "|    ep_rew_mean          | 82.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 1739        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038225684 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.284      |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | 0.00851     |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.97       |\n",
      "|    ep_rew_mean          | 85.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 1814       |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04439192 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.233     |\n",
      "|    explained_variance   | 0.526      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 69.3       |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    value_loss           | 123        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.49      |\n",
      "|    ep_rew_mean          | 84.1      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 30        |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 1879      |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0409722 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.218    |\n",
      "|    explained_variance   | 0.677     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 28.8      |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | 0.00282   |\n",
      "|    value_loss           | 79.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.42        |\n",
      "|    ep_rew_mean          | 84.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1947        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052505568 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.222      |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 40.7        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | 0.00884     |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.81        |\n",
      "|    ep_rew_mean          | 83.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 2017        |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028092777 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.211      |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 43          |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | 0.0181      |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.65       |\n",
      "|    ep_rew_mean          | 83.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 2085       |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01825897 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.215     |\n",
      "|    explained_variance   | 0.687      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | 0.0511     |\n",
      "|    value_loss           | 38.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.97       |\n",
      "|    ep_rew_mean          | 86.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 2154       |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04544265 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.126     |\n",
      "|    explained_variance   | 0.7        |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 25.7       |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | 0.0159     |\n",
      "|    value_loss           | 53.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.84        |\n",
      "|    ep_rew_mean          | 87.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 2223        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030210655 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.00913     |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.87       |\n",
      "|    ep_rew_mean          | 86.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 2295       |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11237052 |\n",
      "|    clip_fraction        | 0.0809     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.135     |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 9.55       |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | 0.0178     |\n",
      "|    value_loss           | 19.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.43        |\n",
      "|    ep_rew_mean          | 84.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 2362        |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021694118 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.102      |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 46.5        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | 0.00398     |\n",
      "|    value_loss           | 79.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.01        |\n",
      "|    ep_rew_mean          | 86.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 2429        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009442297 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0946     |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | 0.00717     |\n",
      "|    value_loss           | 49.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.93       |\n",
      "|    ep_rew_mean          | 86.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 2499       |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03161732 |\n",
      "|    clip_fraction        | 0.0788     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.119     |\n",
      "|    explained_variance   | 0.669      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 30.6       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.00887    |\n",
      "|    value_loss           | 67.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.32        |\n",
      "|    ep_rew_mean          | 84.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 2569        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060221054 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.102      |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.026       |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.97        |\n",
      "|    ep_rew_mean          | 86.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 2640        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061295934 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0928     |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | 0.0181      |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.07        |\n",
      "|    ep_rew_mean          | 86.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 2715        |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030033551 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0958     |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.42       |\n",
      "|    ep_rew_mean          | 85.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 30         |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 2773       |\n",
      "|    total_timesteps      | 83968      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09756045 |\n",
      "|    clip_fraction        | 0.0808     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.147     |\n",
      "|    explained_variance   | 0.737      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 10.6       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.0183     |\n",
      "|    value_loss           | 36         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.76        |\n",
      "|    ep_rew_mean          | 87.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 2880        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035553005 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.162      |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 49.4        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.0128      |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.13        |\n",
      "|    ep_rew_mean          | 86.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 2956        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033778384 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.149      |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | 0.0155      |\n",
      "|    value_loss           | 52.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.4        |\n",
      "|    ep_rew_mean          | 84.8       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 29         |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 3035       |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03546282 |\n",
      "|    clip_fraction        | 0.0891     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.142     |\n",
      "|    explained_variance   | 0.796      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 5.14       |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | 0.0192     |\n",
      "|    value_loss           | 32.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.33        |\n",
      "|    ep_rew_mean          | 85.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 3101        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032000326 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.128      |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | 0.016       |\n",
      "|    value_loss           | 66.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.63        |\n",
      "|    ep_rew_mean          | 88.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 3177        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018580604 |\n",
      "|    clip_fraction        | 0.0669      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.103      |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00018    |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.87        |\n",
      "|    ep_rew_mean          | 87.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 3250        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013841693 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0957     |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 7.9         |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | 0.00847     |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.79        |\n",
      "|    ep_rew_mean          | 87.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 3322        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009439688 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0898     |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 7.89        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00627     |\n",
      "|    value_loss           | 32.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.6         |\n",
      "|    ep_rew_mean          | 88.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 29          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 3398        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012584298 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0804     |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 9.13        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | 0.0135      |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1e47d9e7400>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non rendered environment\n",
    "env = VizDoomGym()\n",
    "#pass convolutional neural network, cnn for image\n",
    "model = PPO('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, learning_rate=0.0001, n_steps=2048)\n",
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "643ea729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6b342bd77f481a7a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6b342bd77f481a7a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {log_basic/PPO_1}  --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "126938f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\OneDrive\\Desktop\\Training-an-AI-to-play-Doom\\logs\n"
     ]
    }
   ],
   "source": [
    "%cd logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0277b794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-37aaeb3019c171fa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-37aaeb3019c171fa\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir PPO_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc28a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd log_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86738920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c50556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-98a385f301021382\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-98a385f301021382\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/log_basic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67ac13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "413e9c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reload model at nk steps, > number of episdoes\n",
    "model10k = PPO.load('./train/train_basic/best_model_30000')\n",
    "model50k = PPO.load('./train/train_basic/best_model_50000')\n",
    "model100k = PPO.load('./train/train_basic/best_model_100000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2621ee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rendered environment\n",
    "env = VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f286a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying 10k steps model to 100 games\n",
    "# Evaluate mean reward for 100 games using loaded model\n",
    "mean_reward, _ = evaluate_policy(model10k, env, n_eval_episodes=100)\n",
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5472e79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying 50k steps model to 100 games\n",
    "mean_reward, _ = evaluate_policy(model50k, env, n_eval_episodes=100)\n",
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37998223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.84"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying 100k steps model to 100 games\n",
    "mean_reward, _ = evaluate_policy(model100k, env, n_eval_episodes=100)\n",
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0004ccf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-08a3f133e145>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'obs' is not defined"
     ]
    }
   ],
   "source": [
    "model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "49ad20e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 0 is 95.0\n",
      "Total Reward for episode 1 is -300.0\n",
      "Total Reward for episode 2 is 95.0\n",
      "Total Reward for episode 3 is 95.0\n",
      "Total Reward for episode 4 is 95.0\n",
      "Total Reward for episode 5 is 95.0\n",
      "Total Reward for episode 6 is 95.0\n",
      "Total Reward for episode 7 is 95.0\n",
      "Total Reward for episode 8 is -315.0\n",
      "Total Reward for episode 9 is -300.0\n",
      "Total Reward for episode 10 is 95.0\n",
      "Total Reward for episode 11 is 95.0\n",
      "Total Reward for episode 12 is 66.0\n",
      "Total Reward for episode 13 is 95.0\n",
      "Total Reward for episode 14 is 95.0\n",
      "Total Reward for episode 15 is -300.0\n",
      "Total Reward for episode 16 is 68.0\n",
      "Total Reward for episode 17 is 59.0\n",
      "Total Reward for episode 18 is 70.0\n",
      "Total Reward for episode 19 is 95.0\n",
      "Total Reward for episode 20 is 95.0\n",
      "Total Reward for episode 21 is -300.0\n",
      "Total Reward for episode 22 is 95.0\n",
      "Total Reward for episode 23 is 95.0\n",
      "Total Reward for episode 24 is -300.0\n",
      "Total Reward for episode 25 is 95.0\n",
      "Total Reward for episode 26 is 95.0\n",
      "Total Reward for episode 27 is 41.0\n",
      "Total Reward for episode 28 is 95.0\n",
      "Total Reward for episode 29 is 95.0\n",
      "Total Reward for episode 30 is 95.0\n",
      "Total Reward for episode 31 is 95.0\n",
      "Total Reward for episode 32 is 95.0\n",
      "Total Reward for episode 33 is 64.0\n",
      "Total Reward for episode 34 is 33.0\n",
      "Total Reward for episode 35 is 70.0\n",
      "Total Reward for episode 36 is 95.0\n",
      "Total Reward for episode 37 is -300.0\n",
      "Total Reward for episode 38 is 95.0\n",
      "Total Reward for episode 39 is -300.0\n",
      "Total Reward for episode 40 is 95.0\n",
      "Total Reward for episode 41 is 95.0\n",
      "Total Reward for episode 42 is 62.0\n",
      "Total Reward for episode 43 is 95.0\n",
      "Total Reward for episode 44 is 95.0\n",
      "Total Reward for episode 45 is 95.0\n",
      "Total Reward for episode 46 is 66.0\n",
      "Total Reward for episode 47 is 95.0\n",
      "Total Reward for episode 48 is -300.0\n",
      "Total Reward for episode 49 is 66.0\n",
      "Total Reward for episode 50 is 95.0\n",
      "Total Reward for episode 51 is 95.0\n",
      "Total Reward for episode 52 is 95.0\n",
      "Total Reward for episode 53 is 56.0\n",
      "Total Reward for episode 54 is 95.0\n",
      "Total Reward for episode 55 is 95.0\n"
     ]
    },
    {
     "ename": "ViZDoomUnexpectedExitException",
     "evalue": "Controlled ViZDoom instance exited unexpectedly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mViZDoomUnexpectedExitException\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-180-c2c70f4c4bb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-147-b393eb591340>\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m#resets game\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscreen_buffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrayscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mViZDoomUnexpectedExitException\u001b[0m: Controlled ViZDoom instance exited unexpectedly."
     ]
    }
   ],
   "source": [
    "for episode in range(100): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        #change to slow down frame\n",
    "        #time.sleep(0.20)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6cb5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
